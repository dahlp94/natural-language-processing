{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae576274-9f51-4205-91e9-6a4558b42abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee4f4e85-ce91-416f-90f8-3eb570f4b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\",\n",
    "                 \"dog cat animal\", \"cat animal dog\", \"cat dog animal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97437857-2c27-458a-9942-816e5a55a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate each word and make a list out of each entries\n",
    "corpus = [sentence.split(\" \") for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57e97697-8dc5-4d8a-a6eb-51ec0f4f94c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['apple', 'banana', 'fruit'],\n",
       " ['banana', 'apple', 'fruit'],\n",
       " ['banana', 'fruit', 'apple'],\n",
       " ['dog', 'cat', 'animal'],\n",
       " ['cat', 'animal', 'dog'],\n",
       " ['cat', 'dog', 'animal']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cce767c-e15d-4566-992c-c7798d3a4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique words\n",
    "vocab = list(set([item for sublist in corpus for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4099073-3235-4c32-8d96-c8bdb673ce14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'fruit', 'apple', 'dog', 'animal', 'banana']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3df272df-3d07-496f-9604-a3767fc5c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a word to index mapping\n",
    "word2index = {v:idx for idx, v in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1254b0d2-d822-4008-a5d0-2ff1fe51ea99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 0,\n",
       " 'fruit': 1,\n",
       " 'apple': 2,\n",
       " 'dog': 3,\n",
       " 'animal': 4,\n",
       " 'banana': 5,\n",
       " '<UNK>': 7}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9217fae8-b5fd-4e5e-9611-c389dfe208c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an unknown word\n",
    "vocab.append(\"<UNK>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da504ad0-c00b-42d3-b41b-97213c0538bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'fruit', 'apple', 'dog', 'animal', 'banana', '<UNK>', '<UNK>']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad7fdc27-4d37-4d0b-9039-a2d20267e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index[\"<UNK>\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8633e640-7657-4dcc-b6d9-79f2ec479895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 0,\n",
       " 'fruit': 1,\n",
       " 'apple': 2,\n",
       " 'dog': 3,\n",
       " 'animal': 4,\n",
       " 'banana': 5,\n",
       " '<UNK>': 0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3561708-07df-4396-8d5f-efd9b6192969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'fruit']\n",
      "['banana', 'apple', 'fruit']\n",
      "['banana', 'fruit', 'apple']\n",
      "['dog', 'cat', 'animal']\n",
      "['cat', 'animal', 'dog']\n",
      "['cat', 'dog', 'animal']\n"
     ]
    }
   ],
   "source": [
    "for c in corpus:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e17fd70-1967-4f68-b6fd-f704b7633c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(batch_size, word_sequence):\n",
    "    \n",
    "    # Make skip gram of one size window\n",
    "    skip_grams = []\n",
    "    # loop each word sequence\n",
    "    # we starts from 1 because 0 has no context\n",
    "    # we stop at second last for the same reason\n",
    "    for sent in corpus:\n",
    "        for i in range(1, len(sent) - 1):\n",
    "            target = word2index[sent[i]]\n",
    "            context = [word2index[sent[i - 1]], word2index[sent[i + 1]]]\n",
    "            for w in context:\n",
    "                skip_grams.append([target, w])\n",
    "    \n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False) #randomly pick without replacement\n",
    "        \n",
    "    for i in random_index:\n",
    "        random_inputs.append([skip_grams[i][0]])  # target, e.g., 2\n",
    "        random_labels.append([skip_grams[i][1]])  # context word, e.g., 3\n",
    "            \n",
    "    return np.array(random_inputs), np.array(random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25446195-b0fe-4ea8-be58-3fe1c0d75cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [[1]\n",
      " [4]]\n",
      "Target:  [[2]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "#testing the method\n",
    "batch_size = 2 # mini-batch size\n",
    "input_batch, target_batch = random_batch(batch_size, corpus)\n",
    "\n",
    "print(\"Input: \", input_batch)\n",
    "print(\"Target: \", target_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1867a131-7caf-41be-984c-a50c3ae96de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super(Skipgram,self).__init__()\n",
    "        self.embedding_v = nn.Embedding(vocab_size, emb_size)\n",
    "        self.embedding_u = nn.Embedding(vocab_size, emb_size)\n",
    "    \n",
    "    def forward(self, center_words, target_words, all_vocabs):\n",
    "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
    "        all_embeds    = self.embedding_u(all_vocabs) #   [batch_size, voc_size, emb_size]\n",
    "        \n",
    "        scores      = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
    "\n",
    "        norm_scores = all_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, voc_size, emb_size] @ [batch_size, emb_size, 1] = [batch_size, voc_size, 1] = [batch_size, voc_size]\n",
    "\n",
    "        nll = -torch.mean(torch.log(torch.exp(scores)/torch.sum(torch.exp(norm_scores), 1).unsqueeze(1))) # log-softmax\n",
    "        # scalar (loss must be scalar)    \n",
    "            \n",
    "        return nll # negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52d7c3bd-87b6-4f75-8109-22384b3b68ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'voc_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m batch_size     \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m# mini-batch size\u001b[39;00m\n\u001b[0;32m      2\u001b[0m embedding_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m#so we can later plot\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model          \u001b[38;5;241m=\u001b[39m Skipgram(voc_size, embedding_size)\n\u001b[0;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'voc_size' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size     = 2 # mini-batch size\n",
    "embedding_size = 2 #so we can later plot\n",
    "model          = Skipgram(voc_size, embedding_size)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c6746-8d86-4820-a527-98593241010f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
